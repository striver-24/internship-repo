{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J46renX2Qn95",
        "outputId": "369c7ce6-faa9-465c-8ef2-2bfba3a877f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.7.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.11/dist-packages (1.37.8)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (13.9.4)\n",
            "Requirement already satisfied: cohere-aws in /usr/local/lib/python3.11/dist-packages (0.8.18)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.28.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: botocore<1.38.0,>=1.37.8 in /usr/local/lib/python3.11/dist-packages (from boto3) (1.37.8)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from boto3) (0.11.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich) (2.18.0)\n",
            "Requirement already satisfied: sagemaker in /usr/local/lib/python3.11/dist-packages (from cohere-aws) (2.241.0)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from botocore<1.38.0,>=1.37.8->boto3) (2.3.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich) (0.1.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: attrs<24,>=23.1.0 in /usr/local/lib/python3.11/dist-packages (from sagemaker->cohere-aws) (23.2.0)\n",
            "Requirement already satisfied: cloudpickle>=2.2.1 in /usr/local/lib/python3.11/dist-packages (from sagemaker->cohere-aws) (3.1.1)\n",
            "Requirement already satisfied: docker in /usr/local/lib/python3.11/dist-packages (from sagemaker->cohere-aws) (7.1.0)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (from sagemaker->cohere-aws) (0.115.11)\n",
            "Requirement already satisfied: google-pasta in /usr/local/lib/python3.11/dist-packages (from sagemaker->cohere-aws) (0.2.0)\n",
            "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from sagemaker->cohere-aws) (6.11.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from sagemaker->cohere-aws) (4.23.0)\n",
            "Requirement already satisfied: omegaconf<=2.3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from sagemaker->cohere-aws) (2.3.0)\n",
            "Requirement already satisfied: pathos in /usr/local/lib/python3.11/dist-packages (from sagemaker->cohere-aws) (0.3.3)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from sagemaker->cohere-aws) (4.3.6)\n",
            "Requirement already satisfied: protobuf<6.0,>=3.12 in /usr/local/lib/python3.11/dist-packages (from sagemaker->cohere-aws) (4.25.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from sagemaker->cohere-aws) (5.9.5)\n",
            "Requirement already satisfied: sagemaker-core<2.0.0,>=1.0.17 in /usr/local/lib/python3.11/dist-packages (from sagemaker->cohere-aws) (1.0.25)\n",
            "Requirement already satisfied: schema in /usr/local/lib/python3.11/dist-packages (from sagemaker->cohere-aws) (0.7.7)\n",
            "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /usr/local/lib/python3.11/dist-packages (from sagemaker->cohere-aws) (1.0.1)\n",
            "Requirement already satisfied: tblib<4,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from sagemaker->cohere-aws) (3.0.0)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (from sagemaker->cohere-aws) (0.34.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker->cohere-aws) (3.21.0)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf<=2.3,>=2.2->sagemaker->cohere-aws) (4.9.3)\n",
            "Requirement already satisfied: mock<5.0,>4.0 in /usr/local/lib/python3.11/dist-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker->cohere-aws) (4.0.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->sagemaker->cohere-aws) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->sagemaker->cohere-aws) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->sagemaker->cohere-aws) (0.23.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi->sagemaker->cohere-aws) (0.46.0)\n",
            "Requirement already satisfied: ppft>=1.7.6.9 in /usr/local/lib/python3.11/dist-packages (from pathos->sagemaker->cohere-aws) (1.7.6.9)\n",
            "Requirement already satisfied: dill>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from pathos->sagemaker->cohere-aws) (0.3.9)\n",
            "Requirement already satisfied: pox>=0.3.5 in /usr/local/lib/python3.11/dist-packages (from pathos->sagemaker->cohere-aws) (0.3.5)\n",
            "Requirement already satisfied: multiprocess>=0.70.17 in /usr/local/lib/python3.11/dist-packages (from pathos->sagemaker->cohere-aws) (0.70.17)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn->sagemaker->cohere-aws) (0.14.0)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi->sagemaker->cohere-aws) (3.7.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi->sagemaker->cohere-aws) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install sentence-transformers transformers nltk spacy pandas torch boto3 rich cohere-aws"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download required NLTK and spaCy resources\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "!python -m spacy download en_core_web_sm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SXGXJanQw9J",
        "outputId": "b421d0f0-3c99-4c78-b2c5-ad3aeba029b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.11/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2025.1.31)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import logging\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "S0axKYXxQ2QY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AWS credentials setup\n",
        "from google.colab import userdata\n",
        "\n",
        "# Securely access AWS credentials stored in Colab secrets\n",
        "aws_access_key = userdata.get('AWS_ACCESS_KEY_ID')\n",
        "aws_secret_key = userdata.get('AWS_SECRET_ACCESS_KEY')\n",
        "aws_region = userdata.get('AWS_REGION', 'us-east-1')\n",
        "\n",
        "# Set environment variables for AWS authentication\n",
        "os.environ['AWS_ACCESS_KEY_ID'] = aws_access_key\n",
        "os.environ['AWS_SECRET_ACCESS_KEY'] = aws_secret_key\n",
        "os.environ['AWS_REGION'] = aws_region\n",
        "\n",
        "# Alternative method if you don't want to use Colab secrets\n",
        "# Uncomment and fill these lines instead\n",
        "# os.environ['AWS_ACCESS_KEY_ID'] = 'your-access-key'\n",
        "# os.environ['AWS_SECRET_ACCESS_KEY'] = 'your-secret-key'\n",
        "# os.environ['AWS_REGION'] = 'us-east-1'\n"
      ],
      "metadata": {
        "id": "mKYoLOheQ6cG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create prompts.py content\n",
        "%%writefile prompts.py\n",
        "# Prompt for guiding the LLM to recommend emission factors\n",
        "lca_assistant_prompt = \"\"\"\n",
        "You are a carbon accounting assistant with expertise in Life Cycle Assessment (LCA) and environmental impact factor mapping.\n",
        "\n",
        "Your goal is to help identify the most appropriate emission factor for a given business activity or product description. Use your knowledge of carbon accounting standards, environmental impact categories, and manufacturing processes to recommend the best match.\n",
        "\n",
        "Business Activity Description: {input}\n",
        "\n",
        "Consider the following potential emission factors that may be relevant:\n",
        "- NAICS categories for EEIO analysis\n",
        "- Ecoinvent processes for detailed LCA\n",
        "\n",
        "Please provide a reasoned recommendation explaining why this emission factor is appropriate for the described activity.\n",
        "\"\"\"\n",
        "\n",
        "# System prompt for Claude 3 Sonnet\n",
        "system_lca_assistant_prompt = \"\"\"\n",
        "You are a carbon accounting expert specializing in emission factor selection for carbon footprinting. Your task is to:\n",
        "\n",
        "1. Analyze the given business activity or product description.\n",
        "2. Recommend the most appropriate emission factor from the provided options.\n",
        "3. Provide a clear justification for your recommendation, explaining why it's the best match.\n",
        "4. If appropriate, suggest an alternative emission factor as a second choice.\n",
        "\n",
        "Your recommendations should be precise, technically sound, and follow carbon accounting best practices.\n",
        "\"\"\"\n",
        "\n",
        "eio_groundtruth_json = {\n",
        "    \"source\": \"\",\n",
        "    \"formConfig\": {\n",
        "        \"fields\": [\n",
        "            {\n",
        "                \"id\": \"\",\n",
        "                \"type\": \"radio\",\n",
        "                \"label\": \"Select the most appropriate NAICS emission factor:\",\n",
        "                \"required\": True,\n",
        "                \"options\": []\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "process_groundtruth_json = {\n",
        "    \"source\": \"\",\n",
        "    \"formConfig\": {\n",
        "        \"fields\": [\n",
        "            {\n",
        "                \"id\": \"\",\n",
        "                \"type\": \"radio\",\n",
        "                \"label\": \"Select the most appropriate process emission factor:\",\n",
        "                \"required\": True,\n",
        "                \"options\": []\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxMyhHMfXWTh",
        "outputId": "3fc2e62b-d727-47c9-c385-4ac8668b46f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing prompts.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from prompts import lca_assistant_prompt, system_lca_assistant_prompt, eio_groundtruth_json, process_groundtruth_json"
      ],
      "metadata": {
        "id": "5zvPpLhtXek5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "import base64\n",
        "import hashlib\n",
        "import re\n",
        "import uuid\n",
        "from time import time\n",
        "import requests\n",
        "from nltk.corpus import stopwords as nltk_stopwords\n",
        "from spacy.lang.en import stop_words as spacy_stopwords\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from rich.logging import RichHandler\n",
        "from rich.progress import Progress, BarColumn, TextColumn, TimeElapsedColumn, TimeRemainingColumn"
      ],
      "metadata": {
        "id": "uuCVuccMXj4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up logging\n",
        "def setup_logging(filename=\"parakeet_debug.log\"):\n",
        "    logger = logging.getLogger(\"eifmap\")\n",
        "    logger.setLevel(logging.INFO)\n",
        "\n",
        "    # Console handler with rich formatting\n",
        "    shell_handler = RichHandler(level=logging.INFO, rich_tracebacks=True, markup=True)\n",
        "    shell_handler.setFormatter(logging.Formatter(\"%(message)s\"))\n",
        "\n",
        "    # File handler for debugging\n",
        "    file_handler = logging.FileHandler(filename, encoding=\"utf-8\")\n",
        "    file_handler.setLevel(logging.INFO)\n",
        "    file_handler.setFormatter(logging.Formatter(\"%(levelname)s %(asctime)s [%(filename)s:%(funcName)s:%(lineno)d] %(message)s\"))\n",
        "\n",
        "    logger.addHandler(shell_handler)\n",
        "    logger.addHandler(file_handler)\n",
        "\n",
        "    return logger\n",
        "\n",
        "logger = setup_logging()"
      ],
      "metadata": {
        "id": "435i6zKuX0HQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def md5_hash(text):\n",
        "    return hashlib.md5(text.encode()).hexdigest()\n",
        "\n",
        "def uuid4_base64():\n",
        "    return base64.b64encode(uuid.uuid4().bytes).decode().replace(\"=\", \"\")\n",
        "\n",
        "def preprocess_texts(texts):\n",
        "    stop_words = spacy_stopwords.STOP_WORDS.union(set(nltk_stopwords.words(\"english\")))\n",
        "\n",
        "    def clean_and_tokenize(text):\n",
        "        text = re.sub(r\"[^\\w\\s]\", \" \", text.lower())\n",
        "        return [word for word in text.split() if word not in stop_words]\n",
        "\n",
        "    if isinstance(texts, np.ndarray):\n",
        "        processed_texts = [clean_and_tokenize(text) for text in texts]\n",
        "    elif isinstance(texts, str):\n",
        "        processed_texts = clean_and_tokenize(texts)\n",
        "    else:\n",
        "        error_message = \"Input must be an np.ndarray or a string.\"\n",
        "        raise TypeError(error_message)\n",
        "\n",
        "    return processed_texts\n",
        "\n",
        "def get_device():\n",
        "    if torch.cuda.is_available():\n",
        "        device = \"cuda\"\n",
        "        logger.info(\"Using GPU to calculate semantic text embedding ...\")\n",
        "    elif torch.backends.mps.is_available():\n",
        "        device = \"mps\"\n",
        "        logger.info(\"Using MPS to calculate semantic text embedding ...\")\n",
        "    else:\n",
        "        device = None\n",
        "        logger.info(\"Using CPU to calculate semantic text embedding ...\")\n",
        "    return device"
      ],
      "metadata": {
        "id": "aXzkw6J3X2ZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Track Progress\n",
        "class RichProgress:\n",
        "    def __init__(self, data, disable_progress=False, description=\"Processing\"):\n",
        "        self.data = data\n",
        "        self.total_iterations = len(data)\n",
        "        self.disable_progress = disable_progress\n",
        "        self.description = description\n",
        "\n",
        "    def __enter__(self):\n",
        "        if not self.disable_progress:\n",
        "            self.progress = Progress(\n",
        "                TextColumn(\"[progress.description]{task.description}\"),\n",
        "                BarColumn(),\n",
        "                TextColumn(\"[progress.percentage]{task.percentage:>3.1f}%\"),\n",
        "                TimeElapsedColumn(),\n",
        "                TimeRemainingColumn(),\n",
        "                TextColumn(\"[progress.custom] {task.fields[rate]}\"),\n",
        "            )\n",
        "\n",
        "            self.task = self.progress.add_task(\n",
        "                f\"{self.description} (0/{self.total_iterations})\",\n",
        "                total=self.total_iterations,\n",
        "                rate=\"\",\n",
        "            )\n",
        "\n",
        "            self.start_time = time()\n",
        "            self.progress.start()\n",
        "            self.last_update_time = time()\n",
        "        else:\n",
        "            self.start_time = time()\n",
        "            self.last_update_time = time()\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, exc_type, exc_value, traceback):\n",
        "        if not self.disable_progress:\n",
        "            self.progress.stop()\n",
        "\n",
        "    def update(self, advance=1):\n",
        "        current_time = time()\n",
        "        elapsed_time = current_time - self.start_time\n",
        "        iteration_time = current_time - self.last_update_time\n",
        "\n",
        "        if not self.disable_progress:\n",
        "            completed = self.progress.tasks[self.task].completed + advance\n",
        "\n",
        "            if iteration_time > 1:\n",
        "                rate = f\"{iteration_time:.2f} sec/iteration\"\n",
        "            else:\n",
        "                iterations_per_second = (completed) / elapsed_time if elapsed_time > 0 else 0\n",
        "                rate = f\"{iterations_per_second:.2f} iterations/sec\"\n",
        "\n",
        "            self.progress.update(\n",
        "                self.task,\n",
        "                advance=advance,\n",
        "                rate=rate,\n",
        "                description=f\"{self.description} ({completed}/{self.total_iterations})\",\n",
        "            )\n",
        "\n",
        "            self.last_update_time = current_time"
      ],
      "metadata": {
        "id": "p0g9NqNHX9i0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ecoinvent_data(ecoinvent_file=\"https://19913970.fs1.hubspotusercontent-na1.net/hubfs/19913970/Database-Overview-for-ecoinvent-v3.9.1-9.xlsx\"):\n",
        "    res = requests.get(ecoinvent_file)\n",
        "    excel_data = pd.ExcelFile(res.content, engine='openpyxl')\n",
        "    eco_df = pd.read_excel(excel_data, sheet_name=2)\n",
        "    eco_df = eco_df.rename(\n",
        "        columns={\n",
        "            'Reference Product Name': 'reference_product',\n",
        "            'Activity UUID & Product UUID': 'impact_factor_id',\n",
        "            'Activity Name': 'impact_factor_name',\n",
        "            'Product Information': 'product_info'\n",
        "        }\n",
        "    )\n",
        "    return eco_df\n",
        "\n",
        "def get_naics_data(\n",
        "    useeio_file=\"https://pasteur.epa.gov/uploads/10.23719/1528686/SupplyChainGHGEmissionFactors_v1.2_NAICS_CO2e_USD2021.csv\",\n",
        "    naics_file=\"https://www.census.gov/naics/2017NAICS/2017_NAICS_Index_File.xlsx\",\n",
        "):\n",
        "    useeio_df = pd.read_csv(useeio_file)\n",
        "    useeio_df = useeio_df[\n",
        "        [\n",
        "            \"2017 NAICS Code\",\n",
        "            \"2017 NAICS Title\",\n",
        "            \"Supply Chain Emission Factors with Margins\",\n",
        "            \"Reference USEEIO Code\",\n",
        "        ]\n",
        "    ]\n",
        "    useeio_df = useeio_df.rename(\n",
        "        columns={\n",
        "            \"2017 NAICS Code\": \"naics_code\",\n",
        "            \"2017 NAICS Title\": \"naics_title\",\n",
        "            \"Supply Chain Emission Factors with Margins\": \"co2e_per_dollar\",\n",
        "            \"Reference USEEIO Code\": \"bea_code\",\n",
        "        }\n",
        "    )\n",
        "    logger.info(f\"Loaded {useeio_df.shape[0]} rows from {useeio_file}\")\n",
        "\n",
        "    naics_df = pd.read_excel(naics_file)\n",
        "    naics_df = naics_df.rename(\n",
        "        columns={\n",
        "            \"NAICS17\": \"naics_code\",\n",
        "            \"INDEX ITEM DESCRIPTION\": \"naics_desc\",\n",
        "        }\n",
        "    )\n",
        "    logger.info(f\"Loaded {naics_df.shape[0]} rows from {naics_file}\")\n",
        "\n",
        "    naics_df = naics_df.merge(useeio_df, on=\"naics_code\", how=\"left\").dropna()\n",
        "    naics_df = naics_df.groupby(\"naics_desc\").first().reset_index()\n",
        "    logger.info(f\"Final shape after merge on naics_code: {naics_df.shape}\")\n",
        "\n",
        "    return naics_df\n",
        "\n",
        "# Recommendation ranking function\n",
        "def get_ranked_list(\n",
        "    text,\n",
        "    semantic_text_model,\n",
        "    eco_df,\n",
        "    eco_ref,\n",
        "    eco_ref_embedding,\n",
        "    lca_type,\n",
        "):\n",
        "    activity_embedding = semantic_text_model.encode([text], show_progress_bar=False, batch_size=1)\n",
        "\n",
        "    k = 10 if lca_type == \"process\" else 20\n",
        "    cosine_scores = util.cos_sim(activity_embedding, eco_ref_embedding)\n",
        "    sorted_cs, indices = cosine_scores.sort(dim=1, descending=True)\n",
        "    topK_sbert = indices.squeeze().numpy()[:k].tolist()\n",
        "    eco_ix = topK_sbert\n",
        "\n",
        "    # Create a ranked list for collecting ground truth\n",
        "    if lca_type == \"process\":\n",
        "        topK_df = pd.DataFrame(eco_ref[eco_ix], columns=[\"reference_product\"]).copy(deep=True).reset_index()\n",
        "        topK_df[\"cosine_score\"] = sorted_cs.squeeze().numpy()[:k]\n",
        "        ranked_list = topK_df.reset_index()[[\"index\", \"reference_product\"]].to_dict(\"records\")\n",
        "        topK_df = topK_df.reset_index()[[\"index\", \"reference_product\"]]\n",
        "    else:\n",
        "        topK_df = eco_df.iloc[eco_ix].copy(deep=True).reset_index()\n",
        "        topK_df[\"cosine_score\"] = sorted_cs.squeeze().numpy()[:k]\n",
        "        ranked_list = topK_df[[\"index\", \"naics_title\", \"naics_desc\", \"naics_code\"]].to_dict(\"records\")\n",
        "\n",
        "    return ranked_list, topK_df\n",
        "\n",
        "# Ground truth preparation functions\n",
        "def prepare_eio_json(entry, clean_text, response, uniq_id):\n",
        "    if len(response) < 1:\n",
        "        error_message = \"Response length must be greater than 1.\"\n",
        "        raise ValueError(error_message)\n",
        "\n",
        "    gt_json = eio_groundtruth_json.copy()\n",
        "    gt_json[\"source\"] = \"*Business Activity*: {}\\n\".format(re.sub(r\"[^\\w\\s]\", \"\", entry))\n",
        "    gt_json[\"source\"] += f\"*AI paraphrased description:* {clean_text}\\n\\n\"\n",
        "    gt_json[\"source\"] += f\"*AI top choice:* {response[0]['naics_title']} ({response[0]['naics_code']})\\n\"\n",
        "    gt_json[\"source\"] += f\"Justification: {response[0]['justification']}\\n\\n\"\n",
        "\n",
        "    if len(response) > 1:\n",
        "        gt_json[\"source\"] += f\"*AI second choice:* {response[1]['naics_title']} ({response[1]['naics_code']})\\n\"\n",
        "        gt_json[\"source\"] += f\"Justification: {response[1]['justification']}\\n\\n\"\n",
        "\n",
        "    gt_json[\"formConfig\"][\"fields\"][0][\"id\"] = uniq_id\n",
        "    gt_json[\"formConfig\"][\"fields\"][0][\"options\"] = pd.concat(\n",
        "        [\n",
        "            pd.DataFrame(response).drop(\"justification\", axis=1).rename(columns={\"naics_code\": \"value\", \"naics_title\": \"label\"}),\n",
        "            pd.DataFrame(\n",
        "                [\n",
        "                    {\"label\": \"Not sure\", \"value\": \"-1\"},\n",
        "                    {\"label\": \"EIF options are inappropriate, no match\", \"value\": \"-2\"},\n",
        "                    {\"label\": \"Activity description is unclear to select an EIF\", \"value\": \"-3\"},\n",
        "                ]\n",
        "            ),\n",
        "        ]\n",
        "    ).to_dict(\"records\")\n",
        "\n",
        "    return gt_json\n",
        "\n",
        "def prepare_process_json(activity_text, response, sel_eco, uniq_id):\n",
        "    gt_json = process_groundtruth_json.copy()\n",
        "    gt_json[\"source\"] = \"*Given description:* {}\\n\".format(re.sub(r\"[^\\w\\s]\", \"\", activity_text))\n",
        "    gt_json[\"source\"] += \"\\n*AI top choice:* {}\\n\".format(response[0][\"impact_factor_name\"])\n",
        "    gt_json[\"source\"] += f\"\\nJustification: {response[0]['justification']}\"\n",
        "\n",
        "    if len(response) > 1:\n",
        "        gt_json[\"source\"] += \"\\n\\n*AI next choice:* {}\\n\".format(response[1][\"impact_factor_name\"])\n",
        "        gt_json[\"source\"] += f\"\\nJustification: {response[1]['justification']}\"\n",
        "\n",
        "    gt_json[\"formConfig\"][\"fields\"][0][\"id\"] = uniq_id\n",
        "    gt_json[\"formConfig\"][\"fields\"][0][\"options\"] = pd.concat(\n",
        "        [\n",
        "            sel_eco[[\"impact_factor_name\", \"impact_factor_id\"]].rename(columns={\"impact_factor_id\": \"value\", \"impact_factor_name\": \"label\"}),\n",
        "            pd.DataFrame(\n",
        "                [\n",
        "                    {\"label\": \"None of the impact factors match\", \"value\": \"0\"},\n",
        "                    {\"label\": \"Not sure\", \"value\": \"-1\"},\n",
        "                    {\"label\": \"Activity text unclear for selection\", \"value\": \"-3\"},\n",
        "                ]\n",
        "            ),\n",
        "        ]\n",
        "    ).to_dict(\"records\")\n",
        "\n",
        "    return gt_json\n",
        "\n",
        "# Activity data loading function\n",
        "def read_activities(\n",
        "    activity_file,\n",
        "    activity_col,\n",
        "    start_idx=0,\n",
        "    end_idx=None,\n",
        "    sheet_name=0,\n",
        "):\n",
        "    logger.info(f\"Reading {activity_file}\")\n",
        "\n",
        "    _, file_extension = os.path.splitext(activity_file)\n",
        "    if file_extension == \".csv\":\n",
        "        activity_df = pd.read_csv(activity_file)\n",
        "    elif file_extension == \".xlsx\":\n",
        "        activity_df = pd.read_excel(activity_file, sheet_name=sheet_name)\n",
        "    else:\n",
        "        error_message = f\"Unsupported file extension: {file_extension}\"\n",
        "        raise ValueError(error_message)\n",
        "\n",
        "    activity_df = activity_df.fillna(\"\").reset_index(drop=True).drop_duplicates()\n",
        "    logger.info(f\"Read {len(activity_df)} activities\")\n",
        "\n",
        "    if end_idx is None:\n",
        "        end_idx = len(activity_df)\n",
        "\n",
        "    logger.info(f\"Will be processing between index {start_idx} and {end_idx}\")\n",
        "\n",
        "    return activity_df.iloc[start_idx:end_idx].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "wA7Uft5gYHjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain_core langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vc5nHtsnZD8p",
        "outputId": "9ff8f41c-0fb5-4e79-d91c-ddac576cdcc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.19)\n",
            "Requirement already satisfied: langchain_core in /usr/local/lib/python3.11/dist-packages (0.3.40)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.19-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.13)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (4.12.2)\n",
            "Collecting langchain_core\n",
            "  Downloading langchain_core-0.3.41-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.20-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain_core) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Downloading langchain_community-0.3.19-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.3.20-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.41-py3-none-any.whl (415 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m415.1/415.1 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain_core, langchain, langchain_community\n",
            "  Attempting uninstall: langchain_core\n",
            "    Found existing installation: langchain-core 0.3.40\n",
            "    Uninstalling langchain-core-0.3.40:\n",
            "      Successfully uninstalled langchain-core-0.3.40\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.19\n",
            "    Uninstalling langchain-0.3.19:\n",
            "      Successfully uninstalled langchain-0.3.19\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.20 langchain_community-0.3.19 langchain_core-0.3.41 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.8.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bedrock client implementation\n",
        "import boto3\n",
        "import json\n",
        "from botocore.config import Config\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_community.llms import Bedrock\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "def get_bedrock_client(\n",
        "    assumed_role=None,\n",
        "    region=None,\n",
        "    runtime=True,\n",
        "):\n",
        "    \"\"\"Create a boto3 client for Amazon Bedrock, with optional configuration overrides.\"\"\"\n",
        "    if region is None:\n",
        "        target_region = os.environ.get(\"AWS_REGION\", os.environ.get(\"AWS_DEFAULT_REGION\"))\n",
        "    else:\n",
        "        target_region = region\n",
        "\n",
        "    logger.info(f\"Create new client\\n Using region: {target_region}\")\n",
        "\n",
        "    session_kwargs = {\"region_name\": target_region}\n",
        "    client_kwargs = {**session_kwargs}\n",
        "\n",
        "    profile_name = os.environ.get(\"AWS_PROFILE\")\n",
        "    if profile_name:\n",
        "        logger.info(f\" Using profile: {profile_name}\")\n",
        "        session_kwargs[\"profile_name\"] = profile_name\n",
        "\n",
        "    retry_config = Config(\n",
        "        region_name=target_region,\n",
        "        retries={\n",
        "            \"max_attempts\": 10,\n",
        "            \"mode\": \"standard\",\n",
        "        },\n",
        "    )\n",
        "\n",
        "    session = boto3.Session(**session_kwargs)\n",
        "\n",
        "    if assumed_role:\n",
        "        logger.info(f\" Using role: {assumed_role}\", end=\"\")\n",
        "        sts = session.client(\"sts\")\n",
        "        response = sts.assume_role(RoleArn=str(assumed_role), RoleSessionName=\"langchain-llm-1\")\n",
        "        logger.info(\" ... successful!\")\n",
        "        client_kwargs[\"aws_access_key_id\"] = response[\"Credentials\"][\"AccessKeyId\"]\n",
        "        client_kwargs[\"aws_secret_access_key\"] = response[\"Credentials\"][\"SecretAccessKey\"]\n",
        "        client_kwargs[\"aws_session_token\"] = response[\"Credentials\"][\"SessionToken\"]\n",
        "\n",
        "    if runtime:\n",
        "        service_name = \"bedrock-runtime\"\n",
        "    else:\n",
        "        service_name = \"bedrock\"\n",
        "\n",
        "    bedrock_client = session.client(service_name=service_name, config=retry_config, **client_kwargs)\n",
        "    logger.info(\"boto3 Bedrock client successfully created!\")\n",
        "    logger.info(str(bedrock_client._endpoint))\n",
        "\n",
        "    return bedrock_client\n",
        "\n",
        "# LCAAssistant implementation\n",
        "class LCAAssistant:\n",
        "    def __init__(self, llm_model=\"anthropic.claude-3-sonnet-20240229-v1:0\"):\n",
        "        self.model_list = [\n",
        "            \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
        "        ]\n",
        "\n",
        "        self.llm_model = llm_model\n",
        "        self.boto3_bedrock = get_bedrock_client()\n",
        "\n",
        "        if self.llm_model in self.model_list:\n",
        "            self.history = []\n",
        "        else:\n",
        "            assistant_model = Bedrock(\n",
        "                model_id=llm_model,\n",
        "                client=self.boto3_bedrock,\n",
        "                model_kwargs={\"temperature\": 0},\n",
        "            )\n",
        "\n",
        "            memory = ConversationBufferMemory(ai_prefix=\"Assistant\")\n",
        "            self.conversation = ConversationChain(llm=assistant_model, verbose=False, memory=memory)\n",
        "            self.conversation.prompt = PromptTemplate.from_template(lca_assistant_prompt)\n",
        "\n",
        "        logger.info(\"LCA Assistant initialized\")\n",
        "\n",
        "    def reset_mem(self):\n",
        "        if self.llm_model in self.model_list:\n",
        "            self.history = []\n",
        "        else:\n",
        "            self.memory.clear()\n",
        "            self.conversation.prompt = PromptTemplate.from_template(lca_assistant_prompt)\n",
        "\n",
        "    def chat(self, text, temperature=0.0):\n",
        "        if self.llm_model in self.model_list:\n",
        "            input_body = dict()\n",
        "            input_body[\"messages\"] = [{\"role\": \"user\", \"content\": text}]\n",
        "            self.history += input_body[\"messages\"]\n",
        "\n",
        "            try:\n",
        "                response = self.boto3_bedrock.invoke_model(\n",
        "                    body=json.dumps(\n",
        "                        {\n",
        "                            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
        "                            \"temperature\": temperature,\n",
        "                            \"max_tokens\": 4096,\n",
        "                            \"system\": system_lca_assistant_prompt,\n",
        "                            \"messages\": self.history,\n",
        "                        }\n",
        "                    ),\n",
        "                    modelId=self.llm_model,\n",
        "                )\n",
        "            except Exception as e:\n",
        "                logger.exception(e)\n",
        "                logger.exception(\"Returning empty string\")\n",
        "                return \"\"\n",
        "\n",
        "            response_body = json.loads(response.get(\"body\").read())\n",
        "            self.history.append({key: response_body[key] for key in [\"role\", \"content\"]})\n",
        "\n",
        "            return response_body.get(\"content\")[0][\"text\"]\n",
        "\n",
        "        return self.conversation.invoke(text)[\"response\"].strip()\n",
        "\n",
        "    def __call__(\n",
        "        self,\n",
        "        text,\n",
        "        format=\"text\",\n",
        "        reset_mem=False,\n",
        "        retries=1,\n",
        "        temperature=0.0,\n",
        "        validation_fn=None,\n",
        "    ):\n",
        "        if reset_mem:\n",
        "            self.reset_mem()\n",
        "\n",
        "        if format == \"python\":\n",
        "            while retries > 0:\n",
        "                try:\n",
        "                    response = self.chat(text, temperature=temperature)\n",
        "                    parsed = ast.literal_eval(response)\n",
        "\n",
        "                    if validation_fn:\n",
        "                        validation_fn(parsed)\n",
        "\n",
        "                    return parsed\n",
        "                except Exception as e:\n",
        "                    logger.exception(e)\n",
        "                    logger.warning(\"Retrying again\")\n",
        "                    text = f\"Your previous response, when parsed with a python code interpreter, caused this python exception: {e!r}\\n. This time generate a response that doesn't cause this exception. ### ORIGINAL INSTRUCTIONS ###\\n\" + text\n",
        "                    retries -= 1\n",
        "\n",
        "            return ast.literal_eval(self.chat(text, temperature=temperature))\n",
        "\n",
        "        return self.chat(text, temperature=temperature)\n"
      ],
      "metadata": {
        "id": "U1utHLu5YvEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main execution flow for Parakeet\n",
        "def parakeet_predict_eeio(\n",
        "    activities_df,\n",
        "    activity_col,\n",
        "    model_name=\"all-MiniLM-L6-v2\",\n",
        "    batch_size=32,\n",
        "    start_idx=0,\n",
        "    end_idx=None,\n",
        "    output_file=\"eeio_predictions.json\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Generate EEIO emission factor recommendations for business activities\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    activities_df : pandas.DataFrame\n",
        "        DataFrame containing business activities\n",
        "    activity_col : str\n",
        "        Column name containing the business activity descriptions\n",
        "    model_name : str\n",
        "        Name of the SentenceTransformer model to use\n",
        "    batch_size : int\n",
        "        Batch size for processing\n",
        "    start_idx : int\n",
        "        Starting index for processing\n",
        "    end_idx : int\n",
        "        Ending index for processing\n",
        "    output_file : str\n",
        "        File to save predictions\n",
        "    \"\"\"\n",
        "    # Load NAICS data\n",
        "    logger.info(\"Loading NAICS data...\")\n",
        "    naics_df = get_naics_data()\n",
        "\n",
        "    # Initialize SentenceTransformer model\n",
        "    device = get_device()\n",
        "    logger.info(f\"Loading {model_name} model...\")\n",
        "    semantic_text_model = SentenceTransformer(model_name, device=device)\n",
        "\n",
        "    # Initialize LCAAssistant\n",
        "    logger.info(\"Initializing LCA Assistant...\")\n",
        "    lca_assistant = LCAAssistant()\n",
        "\n",
        "    # Prepare NAICS embeddings\n",
        "    logger.info(\"Computing NAICS embeddings...\")\n",
        "    naics_ref = naics_df[\"naics_title\"].values\n",
        "    naics_ref_embedding = semantic_text_model.encode(\n",
        "        naics_ref,\n",
        "        batch_size=128,\n",
        "        show_progress_bar=True,\n",
        "        convert_to_tensor=True\n",
        "    )\n",
        "\n",
        "    # Process activities\n",
        "    if end_idx is None:\n",
        "        end_idx = len(activities_df)\n",
        "\n",
        "    activities = activities_df[activity_col].iloc[start_idx:end_idx].tolist()\n",
        "    logger.info(f\"Processing {len(activities)} activities from {start_idx} to {end_idx}\")\n",
        "\n",
        "    results = []\n",
        "\n",
        "    with RichProgress(activities, description=\"Processing activities\") as progress:\n",
        "        for i, activity in enumerate(activities):\n",
        "            activity_id = md5_hash(activity)\n",
        "            logger.info(f\"Processing activity {i+1}/{len(activities)}: {activity[:50]}...\")\n",
        "\n",
        "            # Get ranked list of potential emission factors\n",
        "            ranked_list, topK_df = get_ranked_list(\n",
        "                activity,\n",
        "                semantic_text_model,\n",
        "                naics_df,\n",
        "                naics_ref,\n",
        "                naics_ref_embedding,\n",
        "                \"eio\"\n",
        "            )\n",
        "\n",
        "            # Use LLM to recommend the best emission factor\n",
        "            prompt = f\"\"\"\n",
        "I need to map this business activity to the most appropriate NAICS emission factor for carbon footprinting.\n",
        "\n",
        "Business Activity: {activity}\n",
        "\n",
        "Here are the top candidate NAICS categories from semantic matching:\n",
        "{json.dumps(ranked_list[:5], indent=2)}\n",
        "\n",
        "Please analyze the business activity and candidate NAICS categories, then recommend the most appropriate emission factor.\n",
        "Return your answer as a JSON list with this structure:\n",
        "[\n",
        "  {{\n",
        "    \"naics_code\": \"string\",\n",
        "    \"naics_title\": \"string\",\n",
        "    \"justification\": \"detailed explanation of why this is the best match\"\n",
        "  }},\n",
        "  {{\n",
        "    \"naics_code\": \"string\",\n",
        "    \"naics_title\": \"string\",\n",
        "    \"justification\": \"detailed explanation of why this is a reasonable alternative\"\n",
        "  }}\n",
        "]\n",
        "\"\"\"\n",
        "\n",
        "            try:\n",
        "                response = lca_assistant(prompt, format=\"python\", reset_mem=True)\n",
        "\n",
        "                # Generate paraphrased version of the activity for better understanding\n",
        "                paraphrase_prompt = f\"Paraphrase this business activity in clear, standardized terminology for carbon accounting purposes: '{activity}'\"\n",
        "                clean_text = lca_assistant(paraphrase_prompt, reset_mem=True)\n",
        "\n",
        "                # Prepare result\n",
        "                uniq_id = uuid4_base64()\n",
        "                result = {\n",
        "                    \"activity_id\": activity_id,\n",
        "                    \"activity\": activity,\n",
        "                    \"paraphrased\": clean_text,\n",
        "                    \"ranked_list\": ranked_list,\n",
        "                    \"recommendations\": response,\n",
        "                    \"timestamp\": pd.Timestamp.now().isoformat()\n",
        "                }\n",
        "\n",
        "                results.append(result)\n",
        "\n",
        "                # Prepare ground truth JSON for human validation\n",
        "                gt_json = prepare_eio_json(activity, clean_text, response, uniq_id)\n",
        "\n",
        "                # Save ground truth JSON for this activity\n",
        "                with open(f\"gt_{activity_id}.json\", \"w\") as f:\n",
        "                    json.dump(gt_json, f, indent=2)\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.exception(f\"Error processing activity {i}: {e}\")\n",
        "\n",
        "            progress.update()\n",
        "\n",
        "    # Save all results\n",
        "    with open(output_file, \"w\") as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "\n",
        "    logger.info(f\"Saved {len(results)} predictions to {output_file}\")\n",
        "    return results\n",
        "\n",
        "def parakeet_predict_process(\n",
        "    activities_df,\n",
        "    activity_col,\n",
        "    model_name=\"all-MiniLM-L6-v2\",\n",
        "    batch_size=32,\n",
        "    start_idx=0,\n",
        "    end_idx=None,\n",
        "    output_file=\"process_predictions.json\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Generate process-based LCA emission factor recommendations for business activities\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    activities_df : pandas.DataFrame\n",
        "        DataFrame containing business activities\n",
        "    activity_col : str\n",
        "        Column name containing the business activity descriptions\n",
        "    model_name : str\n",
        "        Name of the SentenceTransformer model to use\n",
        "    batch_size : int\n",
        "        Batch size for processing\n",
        "    start_idx : int\n",
        "        Starting index for processing\n",
        "    end_idx : int\n",
        "        Ending index for processing\n",
        "    output_file : str\n",
        "        File to save predictions\n",
        "    \"\"\"\n",
        "    # Load Ecoinvent data\n",
        "    logger.info(\"Loading Ecoinvent data...\")\n",
        "    eco_df = get_ecoinvent_data()\n",
        "\n",
        "    # Initialize SentenceTransformer model\n",
        "    device = get_device()\n",
        "    logger.info(f\"Loading {model_name} model...\")\n",
        "    semantic_text_model = SentenceTransformer(model_name, device=device)\n",
        "\n",
        "    # Initialize LCAAssistant\n",
        "    logger.info(\"Initializing LCA Assistant...\")\n",
        "    lca_assistant = LCAAssistant()\n",
        "\n",
        "    # Prepare Ecoinvent embeddings\n",
        "    logger.info(\"Computing Ecoinvent embeddings...\")\n",
        "    eco_ref = eco_df[\"reference_product\"].values\n",
        "    eco_ref_embedding = semantic_text_model.encode(\n",
        "        eco_ref,\n",
        "        batch_size=128,\n",
        "        show_progress_bar=True,\n",
        "        convert_to_tensor=True\n",
        "    )\n",
        "\n",
        "    # Process activities\n",
        "    if end_idx is None:\n",
        "        end_idx = len(activities_df)\n",
        "\n",
        "    activities = activities_df[activity_col].iloc[start_idx:end_idx].tolist()\n",
        "    logger.info(f\"Processing {len(activities)} activities from {start_idx} to {end_idx}\")\n",
        "\n",
        "    results = []\n",
        "\n",
        "    with RichProgress(activities, description=\"Processing activities\") as progress:\n",
        "        for i, activity in enumerate(activities):\n",
        "            activity_id = md5_hash(activity)\n",
        "            logger.info(f\"Processing activity {i+1}/{len(activities)}: {activity[:50]}...\")\n",
        "\n",
        "            # Get ranked list of potential emission factors\n",
        "            ranked_list, topK_df = get_ranked_list(\n",
        "                activity,\n",
        "                semantic_text_model,\n",
        "                eco_df,\n",
        "                eco_ref,\n",
        "                eco_ref_embedding,\n",
        "                \"process\"\n",
        "            )\n",
        "\n",
        "            # Use LLM to recommend the best emission factor\n",
        "            prompt = f\"\"\"\n",
        "I need to map this activity to the most appropriate process-based emission factor for detailed LCA.\n",
        "\n",
        "Activity: {activity}\n",
        "\n",
        "Here are the top candidate emission factors from semantic matching:\n",
        "{json.dumps(ranked_list[:5], indent=2)}\n",
        "\n",
        "Please analyze the activity and candidate emission factors, then recommend the most appropriate one.\n",
        "Return your answer as a JSON list with this structure:\n",
        "[\n",
        "  {{\n",
        "    \"impact_factor_id\": \"string\",\n",
        "    \"impact_factor_name\": \"string\",\n",
        "    \"justification\": \"detailed explanation of why this is the best match\"\n",
        "  }},\n",
        "  {{\n",
        "    \"impact_factor_id\": \"string\",\n",
        "    \"impact_factor_name\": \"string\",\n",
        "    \"justification\": \"detailed explanation of why this is a reasonable alternative\"\n",
        "  }}\n",
        "]\n",
        "\"\"\"\n",
        "\n",
        "            try:\n",
        "                response = lca_assistant(prompt, format=\"python\", reset_mem=True)\n",
        "\n",
        "                # Prepare result\n",
        "                uniq_id = uuid4_base64()\n",
        "                result = {\n",
        "                    \"activity_id\": activity_id,\n",
        "                    \"activity\": activity,\n",
        "                    \"ranked_list\": ranked_list,\n",
        "                    \"recommendations\": response,\n",
        "                    \"timestamp\": pd.Timestamp.now().isoformat()\n",
        "                }\n",
        "\n",
        "                results.append(result)\n",
        "\n",
        "                # Prepare ground truth JSON for human validation\n",
        "                gt_json = prepare_process_json(activity, response, eco_df.iloc[topK_df[\"index\"].values], uniq_id)\n",
        "\n",
        "                # Save ground truth JSON for this activity\n",
        "                with open(f\"gt_{activity_id}.json\", \"w\") as f:\n",
        "                    json.dump(gt_json, f, indent=2)\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.exception(f\"Error processing activity {i}: {e}\")\n",
        "\n",
        "            progress.update()\n",
        "\n",
        "    # Save all results\n",
        "    with open(output_file, \"w\") as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "\n",
        "    logger.info(f\"Saved {len(results)} predictions to {output_file}\")\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "ZG5TmYVOZmB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation function to compare predictions against ground truth\n",
        "def evaluate_predictions(predictions_file, ground_truth_file, lca_type=\"eio\"):\n",
        "    \"\"\"\n",
        "    Evaluate Parakeet predictions against ground truth\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    predictions_file : str\n",
        "        File containing Parakeet predictions\n",
        "    ground_truth_file : str\n",
        "        File containing ground truth data\n",
        "    lca_type : str\n",
        "        Type of LCA - 'eio' or 'process'\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    dict\n",
        "        Dictionary containing evaluation metrics\n",
        "    \"\"\"\n",
        "    # Load predictions and ground truth\n",
        "    with open(predictions_file, \"r\") as f:\n",
        "        predictions = json.load(f)\n",
        "\n",
        "    ground_truth = pd.read_csv(ground_truth_file)\n",
        "\n",
        "    # Create dictionaries for easy lookup\n",
        "    pred_dict = {p[\"activity_id\"]: p for p in predictions}\n",
        "\n",
        "    # Calculate metrics\n",
        "    total = 0\n",
        "    correct_top1 = 0\n",
        "    correct_top2 = 0\n",
        "\n",
        "    for _, row in ground_truth.iterrows():\n",
        "        activity_id = row[\"activity_id\"]\n",
        "        true_factor = row[\"true_factor_id\"]\n",
        "\n",
        "        if activity_id not in pred_dict:\n",
        "            continue\n",
        "\n",
        "        pred = pred_dict[activity_id]\n",
        "        total += 1\n",
        "\n",
        "        if lca_type == \"eio\":\n",
        "            if pred[\"recommendations\"][0][\"naics_code\"] == true_factor:\n",
        "                correct_top1 += 1\n",
        "\n",
        "            if len(pred[\"recommendations\"]) > 1 and (\n",
        "                pred[\"recommendations\"][0][\"naics_code\"] == true_factor or\n",
        "                pred[\"recommendations\"][1][\"naics_code\"] == true_factor\n",
        "            ):\n",
        "                correct_top2 += 1\n",
        "        else:\n",
        "            if pred[\"recommendations\"][0][\"impact_factor_id\"] == true_factor:\n",
        "                correct_top1 += 1\n",
        "\n",
        "            if len(pred[\"recommendations\"]) > 1 and (\n",
        "                pred[\"recommendations\"][0][\"impact_factor_id\"] == true_factor or\n",
        "                pred[\"recommendations\"][1][\"impact_factor_id\"] == true_factor\n",
        "            ):\n",
        "                correct_top2 += 1\n",
        "\n",
        "    # Calculate metrics\n",
        "    precision_at_1 = correct_top1 / total if total > 0 else 0\n",
        "    precision_at_2 = correct_top2 / total if total > 0 else 0\n",
        "\n",
        "    metrics = {\n",
        "        \"total\": total,\n",
        "        \"correct_top1\": correct_top1,\n",
        "        \"correct_top2\": correct_top2,\n",
        "        \"precision_at_1\": precision_at_1,\n",
        "        \"precision_at_2\": precision_at_2\n",
        "    }\n",
        "\n",
        "    return metrics\n",
        "\n",
        "# Demo with sample data\n",
        "def demo_parakeet():\n",
        "    \"\"\"\n",
        "    Run a demonstration of Parakeet with sample data\n",
        "    \"\"\"\n",
        "    # Create a sample dataset\n",
        "    sample_data = pd.DataFrame({\n",
        "        \"activity_description\": [\n",
        "            \"COUPLING BRASS COMP GJ X COMP GJ 1-1/4 IN\",\n",
        "            \"NIPPLE GALV IRON 3/8 X 3 IN\",\n",
        "            \"ADAPTER BRASS COMP GJ X MIPT 3/4 IN\",\n",
        "            \"COUPLING BRASS COMP GJ X COMP GJ 1 IN\",\n",
        "            \"TEE BRASS COMP GJ 3/4 IN\"\n",
        "        ]\n",
        "    })\n",
        "\n",
        "    # Save the sample data as CSV\n",
        "    sample_data.to_csv(\"sample_activities.csv\", index=False)\n",
        "\n",
        "    # Run Parakeet for EEIO recommendations\n",
        "    print(\"Running Parakeet for EEIO recommendations...\")\n",
        "    eeio_results = parakeet_predict_eeio(\n",
        "        sample_data,\n",
        "        \"activity_description\",\n",
        "        output_file=\"sample_eeio_predictions.json\"\n",
        "    )\n",
        "\n",
        "    # Print sample results\n",
        "    print(\"\\nSample EEIO Recommendations:\")\n",
        "    for result in eeio_results[:2]:\n",
        "        print(f\"\\nActivity: {result['activity']}\")\n",
        "        print(f\"Paraphrased: {result['paraphrased']}\")\n",
        "        print(\"Top recommendation:\")\n",
        "        print(f\"  NAICS: {result['recommendations'][0]['naics_code']} - {result['recommendations'][0]['naics_title']}\")\n",
        "        print(f\"  Justification: {result['recommendations'][0]['justification'][:200]}...\")\n",
        "\n",
        "    # Run Parakeet for process-based recommendations\n",
        "    print(\"\\nRunning Parakeet for process-based recommendations...\")\n",
        "    process_results = parakeet_predict_process(\n",
        "        sample_data,\n",
        "        \"activity_description\",\n",
        "        output_file=\"sample_process_predictions.json\"\n",
        "    )\n",
        "\n",
        "    # Print sample results\n",
        "    print(\"\\nSample Process-based Recommendations:\")\n",
        "    for result in process_results[:2]:\n",
        "        print(f\"\\nActivity: {result['activity']}\")\n",
        "        print(\"Top recommendation:\")\n",
        "        print(f\"  Process: {result['recommendations'][0]['impact_factor_name']}\")\n",
        "        print(f\"  Justification: {result['recommendations'][0]['justification'][:200]}...\")\n"
      ],
      "metadata": {
        "id": "oqegcrsgZv08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload your own dataset\n",
        "from google.colab import files\n",
        "uploaded = files.upload()  # This will prompt you to upload dataset.csv\n",
        "\n",
        "# Read the uploaded dataset\n",
        "dataset = pd.read_csv(\"parakeet_austin.csv\")\n",
        "print(f\"Loaded dataset with {len(dataset)} rows and columns: {', '.join(dataset.columns)}\")\n",
        "\n",
        "# Define the column containing activity descriptions\n",
        "activity_column = \"description\"  # Replace with your actual column name\n",
        "\n",
        "# Run Parakeet for EEIO recommendations\n",
        "eeio_results = parakeet_predict_eeio(\n",
        "    dataset,\n",
        "    activity_column,\n",
        "    batch_size=32,\n",
        "    output_file=\"eeio_predictions.json\"\n",
        ")\n",
        "\n",
        "ground_truth_uploaded = files.upload()  # Upload ground_truth.csv\n",
        "metrics = evaluate_predictions(\"eeio_predictions.json\", \"ground_truth.csv\", lca_type=\"eio\")\n",
        "print(\"\\nEvaluation metrics:\")\n",
        "for metric, value in metrics.items():\n",
        "    print(f\"  {metric}: {value}\")\n",
        "\n",
        "demo_parakeet()\n",
        "\n",
        "\n",
        "files.download(\"eeio_predictions.json\")\n",
        "files.download(\"sample_eeio_predictions.json\")\n",
        "files.download(\"sample_process_predictions.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "FEWIE1L6Z15f",
        "outputId": "589829ab-e6f7-4a28-9123-14339428f24c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-920d36a9-5862-42f0-a58d-fd6cfe8e7a62\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-920d36a9-5862-42f0-a58d-fd6cfe8e7a62\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving parakeet_austin.csv to parakeet_austin (1).csv\n",
            "Loaded dataset with 4662 rows and columns: COMMODITY, COMMODITY_DESCRIPTION, EXTENDED_DESCRIPTION, CONTRACT_NAME\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m[03/07/25 13:27:02]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading NAICS data\u001b[33m...\u001b[0m                               \u001b]8;id=927085;file://<ipython-input-14-c6319edadc3a>\u001b\\\u001b[2m<ipython-input-14-c6319edadc3a>\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=220016;file://<ipython-input-14-c6319edadc3a>#32\u001b\\\u001b[2m32\u001b[0m\u001b]8;;\u001b\\\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03/07/25 13:27:02] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading NAICS data<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                               <a href=\"file://<ipython-input-14-c6319edadc3a>\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;ipython-input-14-c6319edadc3a&gt;</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://<ipython-input-14-c6319edadc3a>#32\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">32</span></a>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eifmap:Loading NAICS data...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m[03/07/25 13:27:04]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loaded \u001b[1;36m1016\u001b[0m rows from                               \u001b]8;id=160430;file://<ipython-input-11-068238502661>\u001b\\\u001b[2m<ipython-input-11-068238502661>\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=953993;file://<ipython-input-11-068238502661>#36\u001b\\\u001b[2m36\u001b[0m\u001b]8;;\u001b\\\n",
              "\u001b[2;36m                    \u001b[0m         \u001b[4;94mhttps://pasteur.epa.gov/uploads/10.23719/1528686/Su\u001b[0m \u001b[2m                                  \u001b[0m\n",
              "\u001b[2;36m                    \u001b[0m         \u001b[4;94mpplyChainGHGEmissionFactors_v1.2_NAICS_CO2e_USD2021\u001b[0m \u001b[2m                                  \u001b[0m\n",
              "\u001b[2;36m                    \u001b[0m         \u001b[4;94m.csv\u001b[0m                                                \u001b[2m                                  \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03/07/25 13:27:04] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loaded <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1016</span> rows from                               <a href=\"file://<ipython-input-11-068238502661>\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;ipython-input-11-068238502661&gt;</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://<ipython-input-11-068238502661>#36\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">36</span></a>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://pasteur.epa.gov/uploads/10.23719/1528686/Su</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                  </span>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">pplyChainGHGEmissionFactors_v1.2_NAICS_CO2e_USD2021</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                  </span>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">.csv</span>                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                  </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eifmap:Loaded 1016 rows from https://pasteur.epa.gov/uploads/10.23719/1528686/SupplyChainGHGEmissionFactors_v1.2_NAICS_CO2e_USD2021.csv\n"
          ]
        }
      ]
    }
  ]
}